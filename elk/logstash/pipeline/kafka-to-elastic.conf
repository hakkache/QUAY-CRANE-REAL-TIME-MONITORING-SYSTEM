# Logstash Pipeline: Kafka Topics to Elasticsearch
# Consumes Spark-processed data from Kafka and indexes in Elasticsearch

input {
  # Crane Alerts - Critical alerts from sensor data
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["crane_alerts"]
    group_id => "logstash-alerts"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }

  # Alert Summary - Aggregated alert statistics
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["alert_summary"]
    group_id => "logstash-alert-summary"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }

  # Crane Anomalies - Detected anomalies
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["crane_anomalies"]
    group_id => "logstash-anomalies"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }

  # Health Status - Crane health monitoring
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["crane_health_status"]
    group_id => "logstash-health"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }

  # Throughput Metrics
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["crane_throughput"]
    group_id => "logstash-throughput"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }

  # 1-Minute Aggregated Metrics
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["crane_metrics_1min"]
    group_id => "logstash-metrics-1min"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }

  # 5-Minute Aggregated Metrics
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["crane_metrics_5min"]
    group_id => "logstash-metrics-5min"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }

  # Raw Sensor Data (sample for searchability)
  kafka {
    bootstrap_servers => "kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092"
    topics => ["crane_sensors"]
    group_id => "logstash-sensors"
    codec => json
    decorate_events => "basic"
    auto_offset_reset => "earliest"
  }
}

filter {
  # Extract Kafka metadata
  mutate {
    add_field => {
      "kafka_topic" => "%{[@metadata][kafka][topic]}"
      "kafka_partition" => "%{[@metadata][kafka][partition]}"
      "kafka_offset" => "%{[@metadata][kafka][offset]}"
    }
  }

  # Parse timestamp if present
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ", "yyyy-MM-dd HH:mm:ss"]
      target => "@timestamp"
    }
  } else if [window_start] {
    date {
      match => ["window_start", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ"]
      target => "@timestamp"
    }
  }

  # Add index routing based on topic
  if [@metadata][kafka][topic] == "crane_alerts" {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-alerts" } }
  } else if [@metadata][kafka][topic] == "alert_summary" {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-alert-summary" } }
  } else if [@metadata][kafka][topic] == "crane_anomalies" {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-anomalies" } }
  } else if [@metadata][kafka][topic] == "crane_health_status" {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-health" } }
  } else if [@metadata][kafka][topic] == "crane_throughput" {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-throughput" } }
  } else if [@metadata][kafka][topic] =~ /crane_metrics/ {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-metrics" } }
  } else if [@metadata][kafka][topic] == "crane_sensors" {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-sensors" } }
  } else {
    mutate { add_field => { "[@metadata][index_prefix]" => "crane-other" } }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index_prefix]}-%{+YYYY.MM.dd}"
    action => "index"
  }

  # Debug output (comment out in production)
  # stdout { codec => rubydebug }
}
